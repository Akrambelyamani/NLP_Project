{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10133623,"sourceType":"datasetVersion","datasetId":6254172}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import AutoTokenizer\n\n# Load the datasets\nsentences_df = pd.read_csv('/kaggle/input/nlp-project/sentences.csv')  # Replace with actual file path if needed\ndata_df = pd.read_csv('/kaggle/input/nlp-project/data (1).csv')  # Replace with actual file path\n\n# Preview datasets\nprint(sentences_df.head())\nprint(data_df.head())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:38.966968Z","iopub.execute_input":"2024-12-08T02:22:38.967833Z","iopub.status.idle":"2024-12-08T02:22:39.187052Z","shell.execute_reply.started":"2024-12-08T02:22:38.967798Z","shell.execute_reply":"2024-12-08T02:22:39.186134Z"}},"outputs":[{"name":"stdout","text":"                                   darija  \\\n0    homa mkhbbyin chi haja, ana mti99en!   \n1      bayna homa tay7awlo ib9aw mbrrdin.   \n2  loTilat mabaynach fihom mori7in bzzaf.   \n3      ghaliban ghayjrriw 3lih mn lkhdma!   \n4                     Tab3an rah mkta2eb!   \n\n                                                 eng  \\\n0                They're hiding something, I'm sure!   \n1    It's obvious they're trying to keep their cool.   \n2            the hotels don't seem very comfortable.   \n3  he is probably about to be laid off by head of...   \n4                         of course he's depressive!   \n\n                               darija_ar  \n0      هوما مخبّيين شي حاجة, أنا متيقّن!  \n1     باينا هوما تايحاولو إبقاو مبرّدين.  \n2  لوطيلات مابايناش فيهوم موريحين بزّاف.  \n3        غاليبان غايجرّيو عليه من لخدما!  \n4                     طابعان راه مكتاءب!  \n         darija\n0    lbs hwayjk\n1     kayn lbrd\n2    skhon lhal\n3    kaytih tlj\n4  ghadi nsafro\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"\nclass VanillaLSTM(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(VanillaLSTM, self).__init__()\n        self.hidden_size = hidden_size\n        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        out, (hn, cn) = self.lstm(x)\n        out = self.fc(out[:, -1, :])  # Take the last time step output\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:39.188694Z","iopub.execute_input":"2024-12-08T02:22:39.189487Z","iopub.status.idle":"2024-12-08T02:22:39.194980Z","shell.execute_reply.started":"2024-12-08T02:22:39.189446Z","shell.execute_reply":"2024-12-08T02:22:39.194141Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"\n# Use the correct columns\nsentences = sentences_df['darija']  # Source text in Darija\nlabels = sentences_df['eng']  # Target translation in English\n\n# Encode labels\nlabel_encoder = LabelEncoder()\nlabels_encoded = label_encoder.fit_transform(labels)\n\n# Split into train and test sets\ntrain_sentences, test_sentences, train_labels, test_labels = train_test_split(\n    sentences, labels_encoded, test_size=0.2, random_state=42\n)\n\nprint(f\"Train size: {len(train_sentences)}, Test size: {len(test_sentences)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:39.195964Z","iopub.execute_input":"2024-12-08T02:22:39.196221Z","iopub.status.idle":"2024-12-08T02:22:39.254890Z","shell.execute_reply.started":"2024-12-08T02:22:39.196196Z","shell.execute_reply":"2024-12-08T02:22:39.253998Z"}},"outputs":[{"name":"stdout","text":"Train size: 70228, Test size: 17557\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:39.256689Z","iopub.execute_input":"2024-12-08T02:22:39.256965Z","iopub.status.idle":"2024-12-08T02:22:39.675661Z","shell.execute_reply.started":"2024-12-08T02:22:39.256939Z","shell.execute_reply":"2024-12-08T02:22:39.674924Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# 1. Chargement des données\nsentences_df = pd.read_csv(\"/kaggle/input/nlp-project/sentences.csv\")  # Remplacez par le bon chemin\n\n# 2. Préparer les colonnes\nsentences = sentences_df['darija']  # Texte source\nlabels = sentences_df['eng']  # Traductions cibles\n\n# 3. Remplir les valeurs manquantes\nsentences = sentences.fillna('')\nlabels = labels.fillna('')\n\n# 4. Diviser en ensembles d'entraînement et de test\ntrain_sentences, test_sentences, train_labels, test_labels = train_test_split(\n    sentences, labels, test_size=0.2, random_state=42\n)\n\n# 5. Convertir les labels en listes\ntrain_labels_text = list(train_labels)\ntest_labels_text = list(test_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:39.677186Z","iopub.execute_input":"2024-12-08T02:22:39.677499Z","iopub.status.idle":"2024-12-08T02:22:39.862400Z","shell.execute_reply.started":"2024-12-08T02:22:39.677472Z","shell.execute_reply":"2024-12-08T02:22:39.861695Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"print(\"Exemple d'étiquettes d'entraînement :\", train_labels_text[:10])\nprint(\"Exemple d'étiquettes de test :\", test_labels_text[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:39.863573Z","iopub.execute_input":"2024-12-08T02:22:39.863932Z","iopub.status.idle":"2024-12-08T02:22:39.868988Z","shell.execute_reply.started":"2024-12-08T02:22:39.863896Z","shell.execute_reply":"2024-12-08T02:22:39.868161Z"}},"outputs":[{"name":"stdout","text":"Exemple d'étiquettes d'entraînement : ['', '', \"I'm gonna make cake for dessert\", 'You gave me an idea', '', '', '', '', '', '']\nExemple d'étiquettes de test : ['where is the coolest place you traveled?', '', '', '', '', '', '', '', '', '']\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# Filtrer les étiquettes pour s'assurer qu'elles sont des chaînes valides\ntrain_labels_text = [str(label).strip() for label in train_labels_text if isinstance(label, str) and label.strip()]\ntest_labels_text = [str(label).strip() for label in test_labels_text if isinstance(label, str) and label.strip()]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:39.870106Z","iopub.execute_input":"2024-12-08T02:22:39.870445Z","iopub.status.idle":"2024-12-08T02:22:39.892025Z","shell.execute_reply.started":"2024-12-08T02:22:39.870408Z","shell.execute_reply":"2024-12-08T02:22:39.891061Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"train_labels_encoded = tokenizer(list(train_labels_text), padding=True, truncation=True, return_tensors=\"pt\")\ntest_labels_encoded = tokenizer(list(test_labels_text), padding=True, truncation=True, return_tensors=\"pt\")\n\nprint(\"Tokenisation réussie !\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:39.892936Z","iopub.execute_input":"2024-12-08T02:22:39.893219Z","iopub.status.idle":"2024-12-08T02:22:40.728210Z","shell.execute_reply.started":"2024-12-08T02:22:39.893194Z","shell.execute_reply":"2024-12-08T02:22:40.727327Z"}},"outputs":[{"name":"stdout","text":"Tokenisation réussie !\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"print(train_labels_encoded['input_ids'].shape)\nprint(test_labels_encoded['input_ids'].shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:40.729534Z","iopub.execute_input":"2024-12-08T02:22:40.729915Z","iopub.status.idle":"2024-12-08T02:22:40.734608Z","shell.execute_reply.started":"2024-12-08T02:22:40.729874Z","shell.execute_reply":"2024-12-08T02:22:40.733783Z"}},"outputs":[{"name":"stdout","text":"torch.Size([10207, 57])\ntorch.Size([2536, 37])\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"import numpy as np\n\n# Remplacer les NaN par une chaîne vide\ntrain_labels_text = [label if isinstance(label, str) else '' for label in train_labels_text]\ntest_labels_text = [label if isinstance(label, str) else '' for label in test_labels_text]\n\n# Éliminer les étiquettes vides\ntrain_labels_text = [label for label in train_labels_text if label.strip()]\ntest_labels_text = [label for label in test_labels_text if label.strip()]\n\nprint(\"Nettoyage terminé. Échantillons après traitement :\")\nprint(\"Train labels:\", train_labels_text[:10])\nprint(\"Test labels:\", test_labels_text[:10])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:40.736756Z","iopub.execute_input":"2024-12-08T02:22:40.737001Z","iopub.status.idle":"2024-12-08T02:22:40.751380Z","shell.execute_reply.started":"2024-12-08T02:22:40.736977Z","shell.execute_reply":"2024-12-08T02:22:40.750403Z"}},"outputs":[{"name":"stdout","text":"Nettoyage terminé. Échantillons après traitement :\nTrain labels: [\"I'm gonna make cake for dessert\", 'You gave me an idea', 'With eggs?', \"Waitresses aren't interesting\", 'where did you hear this?', 'There you go', 'what are they?', \"i'm trying a new recipe for dinner\", \"i wouldn't recommend the meat\", 'the book is behind the table']\nTest labels: ['where is the coolest place you traveled?', 'Congratulations on your promotion', \"I don't want it\", 'What ingredients?', \"it's ok\", 'At last!', 'I have been to Europe twice', 'take care', 'february', \"i don't like this tea\"]\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"assert all(isinstance(label, str) for label in train_labels_text), \"Problème dans les étiquettes d'entraînement\"\nassert all(isinstance(label, str) for label in test_labels_text), \"Problème dans les étiquettes de test\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:40.752539Z","iopub.execute_input":"2024-12-08T02:22:40.752849Z","iopub.status.idle":"2024-12-08T02:22:40.761922Z","shell.execute_reply.started":"2024-12-08T02:22:40.752824Z","shell.execute_reply":"2024-12-08T02:22:40.761250Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Tokeniser les étiquettes nettoyées\ntrain_labels_encoded = tokenizer(train_labels_text, padding=True, truncation=True, return_tensors=\"pt\")\ntest_labels_encoded = tokenizer(test_labels_text, padding=True, truncation=True, return_tensors=\"pt\")\n\nprint(\"Tokenisation réussie !\")\nprint(f\"Taille des étiquettes tokenisées d'entraînement : {train_labels_encoded['input_ids'].shape}\")\nprint(f\"Taille des étiquettes tokenisées de test : {test_labels_encoded['input_ids'].shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:22:40.763034Z","iopub.execute_input":"2024-12-08T02:22:40.763392Z","iopub.status.idle":"2024-12-08T02:22:41.582675Z","shell.execute_reply.started":"2024-12-08T02:22:40.763329Z","shell.execute_reply":"2024-12-08T02:22:41.581783Z"}},"outputs":[{"name":"stdout","text":"Tokenisation réussie !\nTaille des étiquettes tokenisées d'entraînement : torch.Size([10207, 57])\nTaille des étiquettes tokenisées de test : torch.Size([2536, 37])\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"\n# Initialiser le tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n\n# Première tokenisation pour obtenir les longueurs\ntrain_inputs = tokenizer(list(train_sentences), padding=True, truncation=True, return_tensors=\"pt\")\ntest_inputs = tokenizer(list(test_sentences), padding=True, truncation=True, return_tensors=\"pt\")\ntrain_labels_encoded = tokenizer(list(train_labels_text), padding=True, truncation=True, return_tensors=\"pt\")\ntest_labels_encoded = tokenizer(list(test_labels_text), padding=True, truncation=True, return_tensors=\"pt\")\n\n# Fixer une longueur maximale pour uniformiser les séquences\nmax_length = max(\n    train_inputs['input_ids'].size(1), \n    test_inputs['input_ids'].size(1),\n    train_labels_encoded['input_ids'].size(1), \n    test_labels_encoded['input_ids'].size(1)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:25:12.417883Z","iopub.execute_input":"2024-12-08T02:25:12.418577Z","iopub.status.idle":"2024-12-08T02:25:20.494549Z","shell.execute_reply.started":"2024-12-08T02:25:12.418541Z","shell.execute_reply":"2024-12-08T02:25:20.493741Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"\n# Retokeniser avec la longueur maximale\ntrain_inputs = tokenizer(list(train_sentences), padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\ntest_inputs = tokenizer(list(test_sentences), padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\ntrain_labels_encoded = tokenizer(list(train_labels_text), padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\ntest_labels_encoded = tokenizer(list(test_labels_text), padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n\n# Vérifications finales\nprint(\"Taille des entrées d'entraînement :\", train_inputs['input_ids'].shape)\nprint(\"Taille des étiquettes d'entraînement :\", train_labels_encoded['input_ids'].shape)\nprint(\"Taille des entrées de test :\", test_inputs['input_ids'].shape)\nprint(\"Taille des étiquettes de test :\", test_labels_encoded['input_ids'].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:25:39.478762Z","iopub.execute_input":"2024-12-08T02:25:39.479385Z","iopub.status.idle":"2024-12-08T02:25:47.262208Z","shell.execute_reply.started":"2024-12-08T02:25:39.479325Z","shell.execute_reply":"2024-12-08T02:25:47.260946Z"}},"outputs":[{"name":"stdout","text":"Taille des entrées d'entraînement : torch.Size([70228, 67])\nTaille des étiquettes d'entraînement : torch.Size([10207, 67])\nTaille des entrées de test : torch.Size([17557, 67])\nTaille des étiquettes de test : torch.Size([2536, 67])\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# Ajuster les tailles des entrées et des étiquettes pour qu'elles correspondent\ntrain_inputs['input_ids'] = train_inputs['input_ids'][:len(train_labels_encoded['input_ids'])]\ntest_inputs['input_ids'] = test_inputs['input_ids'][:len(test_labels_encoded['input_ids'])]\n\n# Vérifier à nouveau les tailles après ajustement\nprint(f\"Taille ajustée des entrées d'entraînement : {train_inputs['input_ids'].size(0)}\")\nprint(f\"Taille ajustée des étiquettes d'entraînement : {train_labels_encoded['input_ids'].size(0)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:26:07.223212Z","iopub.execute_input":"2024-12-08T02:26:07.223583Z","iopub.status.idle":"2024-12-08T02:26:07.243166Z","shell.execute_reply.started":"2024-12-08T02:26:07.223552Z","shell.execute_reply":"2024-12-08T02:26:07.242285Z"}},"outputs":[{"name":"stdout","text":"Taille ajustée des entrées d'entraînement : 10207\nTaille ajustée des étiquettes d'entraînement : 10207\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# Ajuster les tailles des entrées et des étiquettes du jeu de test pour qu'elles correspondent\ntest_inputs['input_ids'] = test_inputs['input_ids'][:len(test_labels_encoded['input_ids'])]\ntest_labels_encoded['input_ids'] = test_labels_encoded['input_ids'][:len(test_inputs['input_ids'])]\n\n# Vérifier les tailles après ajustement\nprint(f\"Taille ajustée des entrées de test : {test_inputs['input_ids'].size(0)}\")\nprint(f\"Taille ajustée des étiquettes de test : {test_labels_encoded['input_ids'].size(0)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:26:16.927464Z","iopub.execute_input":"2024-12-08T02:26:16.927779Z","iopub.status.idle":"2024-12-08T02:26:16.933424Z","shell.execute_reply.started":"2024-12-08T02:26:16.927752Z","shell.execute_reply":"2024-12-08T02:26:16.932508Z"}},"outputs":[{"name":"stdout","text":"Taille ajustée des entrées de test : 2536\nTaille ajustée des étiquettes de test : 2536\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\n\n# Créer les jeux de données avec des tailles correspondantes\ntrain_dataset = TensorDataset(train_inputs['input_ids'], train_labels_encoded['input_ids'])\ntest_dataset = TensorDataset(test_inputs['input_ids'], test_labels_encoded['input_ids'])\n\n# Créer les DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nprint(\"DataLoader créé avec succès !\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:26:26.798947Z","iopub.execute_input":"2024-12-08T02:26:26.799780Z","iopub.status.idle":"2024-12-08T02:26:26.805448Z","shell.execute_reply.started":"2024-12-08T02:26:26.799745Z","shell.execute_reply":"2024-12-08T02:26:26.804462Z"}},"outputs":[{"name":"stdout","text":"DataLoader créé avec succès !\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"import torch.optim as optim\n\n# 1. Initialisation du tokenizer (pour la tokenisation)\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n\n# 2. Définition du modèle Seq2SeqLSTM (vous pouvez ajuster selon vos besoins)\nclass Seq2SeqLSTM(nn.Module):\n    def __init__(self, vocab_size, embed_size, hidden_size):\n        super(Seq2SeqLSTM, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.encoder = nn.LSTM(embed_size, hidden_size, batch_first=True)\n        self.decoder = nn.LSTM(embed_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, src, tgt):\n        # Encoder\n        src_embedded = self.embedding(src)\n        _, (hidden, cell) = self.encoder(src_embedded)\n\n        # Decoder\n        tgt_embedded = self.embedding(tgt)\n        outputs, _ = self.decoder(tgt_embedded, (hidden, cell))\n        outputs = self.fc(outputs)\n        return outputs\n\n# 3. Initialisation du modèle, de la perte et de l'optimiseur\nVOCAB_SIZE = tokenizer.vocab_size\nEMBED_SIZE = 256\nHIDDEN_SIZE = 512\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Créer une instance du modèle et l'envoyer sur le device\nmodel = Seq2SeqLSTM(VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE).to(device)\n\n# Définir la fonction de perte et l'optimiseur\ncriterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:26:41.479267Z","iopub.execute_input":"2024-12-08T02:26:41.479600Z","iopub.status.idle":"2024-12-08T02:26:43.884889Z","shell.execute_reply.started":"2024-12-08T02:26:41.479573Z","shell.execute_reply":"2024-12-08T02:26:43.883962Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"EPOCHS = 3  # Nombre d'époques\nmodel.train()  # Mettre le modèle en mode entraînement\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    for batch in train_loader:\n        src, tgt = batch\n        src, tgt = src.to(device), tgt.to(device)\n\n        optimizer.zero_grad()  # Réinitialiser les gradients\n        outputs = model(src, tgt[:, :-1])  # Décalage des cibles pour l'entraînement\n        loss = criterion(outputs.reshape(-1, VOCAB_SIZE), tgt[:, 1:].reshape(-1))  # Calcul de la perte\n\n        loss.backward()  # Rétropropagation\n        optimizer.step()  # Mise à jour des poids\n\n        total_loss += loss.item()\n\n    print(f\"Époque {epoch + 1}/{EPOCHS}, Perte moyenne : {total_loss / len(train_loader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:26:53.575682Z","iopub.execute_input":"2024-12-08T02:26:53.576661Z","iopub.status.idle":"2024-12-08T02:29:16.605974Z","shell.execute_reply.started":"2024-12-08T02:26:53.576625Z","shell.execute_reply":"2024-12-08T02:29:16.605029Z"}},"outputs":[{"name":"stdout","text":"Époque 1/3, Perte moyenne : 5.688161609314826\nÉpoque 2/3, Perte moyenne : 4.519168390375693\nÉpoque 3/3, Perte moyenne : 4.050442573045115\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"model.eval()  # Mettre le modèle en mode évaluation\ntotal_test_loss = 0\n\nwith torch.no_grad():  # Désactive la mise à jour des gradients pendant l'évaluation\n    for batch in test_loader:\n        src, tgt = batch\n        src, tgt = src.to(device), tgt.to(device)\n\n        outputs = model(src, tgt[:, :-1])\n        loss = criterion(outputs.reshape(-1, VOCAB_SIZE), tgt[:, 1:].reshape(-1))\n        total_test_loss += loss.item()\n\nprint(f\"Perte moyenne sur le test : {total_test_loss / len(test_loader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:29:32.439967Z","iopub.execute_input":"2024-12-08T02:29:32.440687Z","iopub.status.idle":"2024-12-08T02:29:36.483452Z","shell.execute_reply.started":"2024-12-08T02:29:32.440650Z","shell.execute_reply":"2024-12-08T02:29:36.482608Z"}},"outputs":[{"name":"stdout","text":"Perte moyenne sur le test : 4.380667638778687\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"\nVOCAB_SIZE = tokenizer.vocab_size\nEMBED_SIZE = 256\nHIDDEN_SIZE = 512\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = Seq2SeqLSTM(VOCAB_SIZE, EMBED_SIZE, HIDDEN_SIZE).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:29:47.184182Z","iopub.execute_input":"2024-12-08T02:29:47.184509Z","iopub.status.idle":"2024-12-08T02:29:48.175879Z","shell.execute_reply.started":"2024-12-08T02:29:47.184481Z","shell.execute_reply":"2024-12-08T02:29:48.175133Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"\nfrom torch.utils.data import DataLoader, TensorDataset\n\ntrain_dataset = TensorDataset(train_inputs['input_ids'], train_labels_encoded['input_ids'])\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nEPOCHS = 3\n\nfor epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        src, tgt = batch\n        src, tgt = src.to(device), tgt.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(src, tgt[:, :-1])\n        loss = criterion(outputs.reshape(-1, VOCAB_SIZE), tgt[:, 1:].reshape(-1))\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss / len(train_loader)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:30:12.535907Z","iopub.execute_input":"2024-12-08T02:30:12.536740Z","iopub.status.idle":"2024-12-08T02:32:35.226111Z","shell.execute_reply.started":"2024-12-08T02:30:12.536705Z","shell.execute_reply":"2024-12-08T02:32:35.225080Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3, Loss: 5.658261033061156\nEpoch 2/3, Loss: 4.479279763272563\nEpoch 3/3, Loss: 4.0239766144827245\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"\nwith torch.no_grad():\n    for i in range(5):  # Show 5 examples\n        src = test_inputs['input_ids'][i].unsqueeze(0).to(device)\n        tgt = test_labels_encoded['input_ids'][i].unsqueeze(0).to(device)\n\n        outputs = model(src, tgt[:, :-1])\n        predictions = outputs.argmax(dim=-1)\n\n        print(\"Source Sentence:\", tokenizer.decode(src.squeeze(), skip_special_tokens=True))\n        print(\"Expected Translation:\", tokenizer.decode(tgt.squeeze(), skip_special_tokens=True))\n        print(\"Predicted Translation:\", tokenizer.decode(predictions.squeeze(), skip_special_tokens=True))\n        print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:35:11.298738Z","iopub.execute_input":"2024-12-08T02:35:11.299429Z","iopub.status.idle":"2024-12-08T02:35:11.343502Z","shell.execute_reply.started":"2024-12-08T02:35:11.299396Z","shell.execute_reply":"2024-12-08T02:35:11.342572Z"}},"outputs":[{"name":"stdout","text":"Source Sentence: chnou hia a7ssn blassa saferti liha?\nExpected Translation: where is the coolest place you traveled?\nPredicted Translation: I is the best??? '????????????\n--------------------------------------------------\nSource Sentence: sir bniya ou rged m3a l7eya\nExpected Translation: Congratulations on your promotion\nPredicted Translation: Igratulations thes,\n--------------------------------------------------\nSource Sentence: jarabt dart chbkat dlbasla obtata\nExpected Translation: I don ' t want it\nPredicted Translation: I ' ' t have to\n--------------------------------------------------\nSource Sentence: rah ba9i l7al\nExpected Translation: What ingredients?\nPredicted Translation: I do you do you???????????????????????????\n--------------------------------------------------\nSource Sentence: raki sme3ti tbib achnou galik\nExpected Translation: it ' s ok\nPredicted Translation: I ' s a\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"torch.save(model.state_dict(), 'seq2seq_model.pth')\nprint(\"Modèle sauvegardé avec succès !\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T02:36:06.626031Z","iopub.execute_input":"2024-12-08T02:36:06.626833Z","iopub.status.idle":"2024-12-08T02:36:07.395327Z","shell.execute_reply.started":"2024-12-08T02:36:06.626798Z","shell.execute_reply":"2024-12-08T02:36:07.394412Z"}},"outputs":[{"name":"stdout","text":"Modèle sauvegardé avec succès !\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}